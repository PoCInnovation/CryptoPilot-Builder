#!/usr/bin/env python3
"""
Tests d'int√©gration pour le dashboard AutoWallet avec les nouvelles sous-pages
Valide que les composants News+Alerts et Full Pipeline fonctionnent correctement
"""

import sys
import os
import asyncio
import unittest
from datetime import datetime, timedelta
from unittest.mock import patch, MagicMock

# Ajouter le r√©pertoire parent au path Python
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.news_service import news_service, NewsItem
from services.ai_analyzer import ai_analyzer, MarketContext
from services.autowallet_service import autowallet_service
from services.alert_service import alert_service

class TestDashboardIntegration(unittest.TestCase):
    """Tests d'int√©gration pour le dashboard"""
    
    def setUp(self):
        """Configuration des tests"""
        self.test_user_id = "test_dashboard_user_456"
        
    def tearDown(self):
        """Nettoyage apr√®s les tests"""
        # Nettoyer les donn√©es de test
        try:
            autowallet_service.delete_autowallet(self.test_user_id)
        except:
            pass
    
    def test_news_alerts_dashboard_data_flow(self):
        """Test le flux de donn√©es pour le dashboard News+Alerts"""
        print("üß™ Test du flux de donn√©es News+Alerts...")
        
        try:
            # 1. Cr√©er une configuration autowallet
            test_config = {
                'is_active': True,
                'analysis_interval': 5,
                'max_investment_per_trade': 100.0,
                'risk_tolerance': 'medium',
                'investment_strategy': 'balanced',
                'min_confidence_threshold': 0.3,
                'crypto_whitelist': ['BTC', 'ETH', 'ADA']
            }
            
            autowallet_id = autowallet_service.create_autowallet(self.test_user_id, test_config)
            self.assertIsNotNone(autowallet_id)
            print("‚úÖ Configuration autowallet cr√©√©e")
            
            # 2. R√©cup√©rer des news r√©centes
            recent_news = news_service.get_recent_news(hours=24)
            self.assertIsInstance(recent_news, list)
            print(f"‚úÖ {len(recent_news)} news r√©cup√©r√©es pour le dashboard")
            
            # 3. G√©n√©rer des alertes √† partir des news
            if recent_news:
                market_context = ai_analyzer.get_market_context()
                alerts = ai_analyzer.analyze_news_for_investment(recent_news[:3], market_context)
                self.assertIsInstance(alerts, list)
                print(f"‚úÖ {len(alerts)} alertes g√©n√©r√©es pour le dashboard")
                
                # 4. V√©rifier la structure des donn√©es pour l'interface
                for alert in alerts:
                    self.assertIsNotNone(alert.id)
                    self.assertIsNotNone(alert.crypto_symbol)
                    self.assertIn(alert.alert_type, ["buy", "sell", "hold"])
                    self.assertGreaterEqual(alert.confidence_score, 0.0)
                    self.assertLessEqual(alert.confidence_score, 1.0)
                    self.assertIsNotNone(alert.reasoning)
                    self.assertIsNotNone(alert.created_at)
                
                print("‚úÖ Structure des alertes valid√©e pour l'interface")
            
            # 5. Tester l'analyse manuelle
            if recent_news:
                news_ids = [news.id for news in recent_news[:2]]
                manual_alerts = autowallet_service.analyze_news_manually(self.test_user_id, news_ids)
                self.assertIsInstance(manual_alerts, list)
                print(f"‚úÖ Analyse manuelle: {len(manual_alerts)} alertes")
            
        except Exception as e:
            print(f"‚ùå Erreur dans le flux News+Alerts: {e}")
            self.fail(f"Le flux de donn√©es News+Alerts a √©chou√©: {e}")
    
    def test_full_pipeline_dashboard_data_flow(self):
        """Test le flux de donn√©es pour le dashboard Full Pipeline"""
        print("üß™ Test du flux de donn√©es Full Pipeline...")
        
        try:
            # 1. Tester l'int√©gration avec le pipeline manager
            from pipeline.utils.pipeline_manager import PipelineManager
            
            pipeline_manager = PipelineManager()
            
            # V√©rifier que tous les agents sont pr√©sents
            expected_agents = [
                "unified_data_collector",
                "predictor", 
                "strategy",
                "trader",
                "logger"
            ]
            
            for agent_name in expected_agents:
                self.assertIn(agent_name, pipeline_manager.agents)
                self.assertIn(agent_name, pipeline_manager.agent_status)
            
            print("‚úÖ Tous les agents du pipeline sont pr√©sents")
            
            # 2. Tester l'ex√©cution du collecteur unifi√©
            unified_data = pipeline_manager._execute_unified_data_collector_sync()
            if unified_data:
                self.assertIsInstance(unified_data, dict)
                self.assertIn("market_data", unified_data)
                self.assertIn("news_data", unified_data)
                self.assertIn("alerts_data", unified_data)
                self.assertIn("timestamp", unified_data)
                print("‚úÖ Donn√©es unifi√©es g√©n√©r√©es pour le pipeline")
            
            # 3. Tester l'ex√©cution de la s√©quence compl√®te
            pipeline_data = pipeline_manager._execute_pipeline_sequence_sync()
            if pipeline_data:
                self.assertIsNotNone(pipeline_data.timestamp)
                self.assertIsNotNone(pipeline_data.symbol)
                self.assertIsNotNone(pipeline_data.metadata)
                print("‚úÖ S√©quence compl√®te du pipeline ex√©cut√©e")
            
            # 4. V√©rifier les statistiques du pipeline
            stats = pipeline_manager.get_pipeline_stats()
            self.assertIsInstance(stats, dict)
            self.assertIn("total_executions", stats)
            self.assertIn("success_rate", stats)
            self.assertIn("average_execution_time", stats)
            print("‚úÖ Statistiques du pipeline r√©cup√©r√©es")
            
        except Exception as e:
            print(f"‚ùå Erreur dans le flux Full Pipeline: {e}")
            self.fail(f"Le flux de donn√©es Full Pipeline a √©chou√©: {e}")
    
    def test_dashboard_refresh_functionality(self):
        """Test la fonctionnalit√© de rafra√Æchissement du dashboard"""
        print("üß™ Test de la fonctionnalit√© de rafra√Æchissement...")
        
        try:
            # 1. Cr√©er une configuration
            test_config = {
                'is_active': True,
                'analysis_interval': 1,  # Intervalle court pour les tests
                'max_investment_per_trade': 50.0,
                'risk_tolerance': 'low',
                'investment_strategy': 'conservative',
                'min_confidence_threshold': 0.5,
                'crypto_whitelist': ['BTC', 'ETH']
            }
            
            autowallet_id = autowallet_service.create_autowallet(self.test_user_id, test_config)
            print("‚úÖ Configuration cr√©√©e pour le test de rafra√Æchissement")
            
            # 2. D√©marrer le monitoring
            autowallet_service.start_monitoring(self.test_user_id)
            print("‚úÖ Monitoring d√©marr√©")
            
            # 3. Attendre un peu pour que le monitoring collecte des donn√©es
            import time
            time.sleep(2)
            
            # 4. V√©rifier que des donn√©es ont √©t√© collect√©es
            status = autowallet_service.get_autowallet_status(self.test_user_id)
            self.assertTrue(status.get('is_monitoring', False))
            print("‚úÖ Monitoring actif confirm√©")
            
            # 5. Arr√™ter le monitoring
            autowallet_service.stop_monitoring(self.test_user_id)
            print("‚úÖ Monitoring arr√™t√©")
            
        except Exception as e:
            print(f"‚ùå Erreur dans le test de rafra√Æchissement: {e}")
            self.fail(f"Le test de rafra√Æchissement a √©chou√©: {e}")
    
    def test_alert_service_integration(self):
        """Test l'int√©gration avec le service d'alertes"""
        print("üß™ Test d'int√©gration avec le service d'alertes...")
        
        try:
            # 1. Ajouter un canal d'alerte de test
            channel_id = alert_service.add_alert_channel(
                self.test_user_id,
                'email',
                {'email': 'test@example.com'}
            )
            self.assertIsNotNone(channel_id)
            print(f"‚úÖ Canal d'alerte ajout√©: {channel_id}")
            
            # 2. V√©rifier que le canal est dans la liste
            user_channels = alert_service.get_user_channels(self.test_user_id)
            self.assertIsInstance(user_channels, list)
            self.assertGreater(len(user_channels), 0)
            print(f"‚úÖ {len(user_channels)} canal(s) d'alerte trouv√©(s)")
            
            # 3. Cr√©er une alerte de test
            from services.news_service import InvestmentAlert
            
            test_alert = InvestmentAlert(
                id="test_alert_123",
                news_id="test_news_123",
                crypto_symbol="BTC",
                alert_type="buy",
                confidence_score=0.8,
                reasoning="Test d'int√©gration du service d'alertes",
                created_at=datetime.now(),
                priority="high"
            )
            
            # 4. Tester l'envoi d'alerte (simulation)
            # Note: En production, cela enverrait vraiment l'email
            success = alert_service.send_investment_alert(test_alert, self.test_user_id)
            # Le succ√®s peut √™tre False si SMTP n'est pas configur√©, c'est normal
            print(f"‚úÖ Envoi d'alerte test√© (succ√®s: {success})")
            
            # 5. Nettoyer
            alert_service.remove_alert_channel(self.test_user_id, channel_id)
            print("‚úÖ Canal d'alerte supprim√©")
            
        except Exception as e:
            print(f"‚ùå Erreur dans l'int√©gration des alertes: {e}")
            self.fail(f"L'int√©gration des alertes a √©chou√©: {e}")
    
    def test_dashboard_error_handling(self):
        """Test la gestion d'erreurs du dashboard"""
        print("üß™ Test de gestion d'erreurs du dashboard...")
        
        try:
            # 1. Tester avec un utilisateur inexistant
            status = autowallet_service.get_autowallet_status("user_inexistant")
            self.assertIn("error", status)
            print("‚úÖ Gestion d'erreur pour utilisateur inexistant")
            
            # 2. Tester l'analyse avec des IDs de news invalides
            alerts = autowallet_service.analyze_news_manually(self.test_user_id, ["invalid_id"])
            self.assertIsInstance(alerts, list)
            self.assertEqual(len(alerts), 0)
            print("‚úÖ Gestion d'erreur pour IDs de news invalides")
            
            # 3. Tester la r√©cup√©ration d'historique pour un utilisateur sans trades
            history = autowallet_service.get_trade_history(self.test_user_id)
            self.assertIsInstance(history, list)
            print("‚úÖ Gestion d'historique vide")
            
            # 4. Tester les alertes pour un utilisateur sans configuration
            user_alerts = autowallet_service.get_user_alerts("user_inexistant")
            self.assertIsInstance(user_alerts, list)
            print("‚úÖ Gestion d'alertes pour utilisateur inexistant")
            
        except Exception as e:
            print(f"‚ùå Erreur dans le test de gestion d'erreurs: {e}")
            self.fail(f"La gestion d'erreurs a √©chou√©: {e}")
    
    def test_dashboard_performance(self):
        """Test les performances du dashboard"""
        print("üß™ Test des performances du dashboard...")
        
        try:
            import time
            
            # 1. Test de performance de la collecte de news
            start_time = time.time()
            recent_news = news_service.get_recent_news(hours=24)
            news_time = time.time() - start_time
            print(f"‚úÖ Collecte de news: {news_time:.2f}s pour {len(recent_news)} news")
            
            # 2. Test de performance de l'analyse IA
            if recent_news:
                start_time = time.time()
                market_context = ai_analyzer.get_market_context()
                alerts = ai_analyzer.analyze_news_for_investment(recent_news[:5], market_context)
                analysis_time = time.time() - start_time
                print(f"‚úÖ Analyse IA: {analysis_time:.2f}s pour {len(alerts)} alertes")
            
            # 3. Test de performance du pipeline manager
            from pipeline.utils.pipeline_manager import PipelineManager
            pipeline_manager = PipelineManager()
            
            start_time = time.time()
            unified_data = pipeline_manager._execute_unified_data_collector_sync()
            pipeline_time = time.time() - start_time
            print(f"‚úÖ Pipeline unifi√©: {pipeline_time:.2f}s")
            
            # V√©rifier que les performances sont acceptables (< 5 secondes)
            self.assertLess(news_time, 5.0, "La collecte de news est trop lente")
            if recent_news:
                self.assertLess(analysis_time, 5.0, "L'analyse IA est trop lente")
            self.assertLess(pipeline_time, 5.0, "Le pipeline est trop lent")
            
        except Exception as e:
            print(f"‚ùå Erreur dans le test de performance: {e}")
            self.fail(f"Le test de performance a √©chou√©: {e}")

def run_dashboard_integration_tests():
    """Lance tous les tests d'int√©gration du dashboard"""
    print("üöÄ D√©marrage des tests d'int√©gration du dashboard")
    print("=" * 70)
    
    # Cr√©er la suite de tests
    test_suite = unittest.TestLoader().loadTestsFromTestCase(TestDashboardIntegration)
    
    # Ex√©cuter les tests
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # R√©sum√© des r√©sultats
    print("\n" + "=" * 70)
    print("üìä R√âSUM√â DES TESTS D'INT√âGRATION DU DASHBOARD")
    print("=" * 70)
    
    total_tests = result.testsRun
    failures = len(result.failures)
    errors = len(result.errors)
    successes = total_tests - failures - errors
    
    print(f"Tests ex√©cut√©s: {total_tests}")
    print(f"‚úÖ R√©ussis: {successes}")
    print(f"‚ùå √âchecs: {failures}")
    print(f"üí• Erreurs: {errors}")
    
    if failures > 0:
        print("\nüîç D√âTAILS DES √âCHECS:")
        for test, traceback in result.failures:
            print(f"  - {test}: {traceback.split('AssertionError: ')[-1].split('\\n')[0]}")
    
    if errors > 0:
        print("\nüí• D√âTAILS DES ERREURS:")
        for test, traceback in result.errors:
            print(f"  - {test}: {traceback.split('\\n')[-2]}")
    
    success_rate = (successes / total_tests) * 100 if total_tests > 0 else 0
    print(f"\nüìà Taux de r√©ussite: {success_rate:.1f}%")
    
    if success_rate >= 80:
        print("üéâ Tests d'int√©gration du dashboard r√©ussis !")
        print("   Les sous-pages News+Alerts et Full Pipeline sont op√©rationnelles.")
        return 0
    else:
        print("‚ö†Ô∏è  Certains tests ont √©chou√©. V√©rifiez la configuration.")
        return 1

if __name__ == "__main__":
    exit_code = run_dashboard_integration_tests()
    sys.exit(exit_code)
